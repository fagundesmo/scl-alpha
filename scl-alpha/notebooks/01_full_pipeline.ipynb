{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-title",
   "metadata": {},
   "source": [
    "# SCL-Alpha: ML-Driven Supply-Chain & Logistics Alpha\n",
    "\n",
    "**End-to-end walkthrough** â€” data â†’ features â†’ models â†’ backtest â†’ metrics\n",
    "\n",
    "**Universe:** UPS Â· FDX Â· XPO Â· CHRW Â· JBHT Â· UNP Â· CSX Â· MATX Â· GXO Â· EXPD  \n",
    "**Models:** Ridge Regression Â· Random Forest Â· XGBoost  \n",
    "**Target:** 5-day forward return (regression)  \n",
    "**Backtest:** Walk-forward (expanding window, weekly rebalance)\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Copy `.env.example` â†’ `.env` and add your free FRED API key from https://fred.stlouisfed.org/docs/api/api_key.html\n",
    "\n",
    "> **Run from the project root** (`scl-alpha/`), not from inside `notebooks/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup-header",
   "metadata": {},
   "source": [
    "## 0 Â· Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Standard path fix: run from project root â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure we can import from src/\n",
    "ROOT = Path(os.getcwd())\n",
    "if ROOT.name == \"notebooks\":          # if you launched from notebooks/ dir\n",
    "    ROOT = ROOT.parent\n",
    "    os.chdir(ROOT)\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(f\"Project root: {ROOT}\")\n",
    "\n",
    "# â”€â”€ Load environment variables (.env â†’ FRED_API_KEY) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# â”€â”€ Silence verbose warnings in a notebook context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "print(f\"pandas  {pd.__version__}\")\n",
    "print(f\"numpy   {np.__version__}\")\n",
    "print(\"Setup complete âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 Â· Pull Data\n",
    "\n",
    "We download:\n",
    "- **OHLCV prices** from Yahoo Finance via `yfinance` (cached as parquet)\n",
    "- **Macro series** from FRED (VIX, diesel prices, ISM PMI, 10Y yield, jobless claims)\n",
    "- **Fama-French factors** from Ken French's data library (used as benchmark returns)\n",
    "\n",
    "> First run takes ~30 seconds; subsequent runs are instant (cached)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-data-pull",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import TICKERS, ALL_SYMBOLS, DATA_START, DATA_END\n",
    "from src.data_pull import pull_all\n",
    "\n",
    "print(f\"Ticker universe ({len(TICKERS)} stocks): {TICKERS}\")\n",
    "print(f\"Benchmarks: IYT, SPY\")\n",
    "print(f\"Date range : {DATA_START} â†’ {DATA_END}\")\n",
    "print()\n",
    "\n",
    "raw = pull_all()\n",
    "print(f\"\\nRaw panel shape: {raw.shape}\")\n",
    "print(f\"Columns: {list(raw.columns)}\")\n",
    "raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-data-inspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Basic data quality checks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=== Date range per ticker ===\")\n",
    "summary = (\n",
    "    raw.reset_index()\n",
    "    .groupby(\"ticker\")[\"date\"]\n",
    "    .agg([\"min\", \"max\", \"count\"])\n",
    "    .rename(columns={\"min\": \"first\", \"max\": \"last\", \"count\": \"rows\"})\n",
    ")\n",
    "print(summary.to_string())\n",
    "\n",
    "print(\"\\n=== Null counts ===\")\n",
    "print(raw.isnull().sum()[raw.isnull().sum() > 0].to_string() or \"No nulls.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-features-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 Â· Feature Engineering\n",
    "\n",
    "All features are computed **at time t using only information available up to time t** (no look-ahead bias).\n",
    "\n",
    "| Group | Features |\n",
    "|---|---|\n",
    "| Price returns | `ret_1d`, `ret_5d`, `ret_20d` |\n",
    "| Volatility | `vol_20d` |\n",
    "| Momentum | `rsi_14`, `volume_ratio_20d` |\n",
    "| Relative strength | `ret_vs_iyt_5d`, `ret_vs_spy_5d` |\n",
    "| Macro | `vix_level`, `vix_change_5d`, `diesel_change_4w`, `ism_pmi`, `dgs10`, `claims_change_4w` |\n",
    "| Advanced | `rolling_beta_60d`, `vol_regime`, `momentum_rank`, `mean_reversion_5d` |\n",
    "| **Target** | `target_ret_5d_fwd` (5-day forward return â€” NOT a feature) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08-features-build",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import build_features, FEATURE_COLUMNS\n",
    "\n",
    "panel = build_features(raw)\n",
    "\n",
    "print(f\"Panel shape after feature engineering: {panel.shape}\")\n",
    "print(f\"\\nFeature columns ({len(FEATURE_COLUMNS)}):\")\n",
    "for i, col in enumerate(FEATURE_COLUMNS, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTarget in FEATURE_COLUMNS: {'target_ret_5d_fwd' in FEATURE_COLUMNS}  (should be False)\")\n",
    "\n",
    "panel[FEATURE_COLUMNS + ['target_ret_5d_fwd']].describe().T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09-target-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_target_distribution\n",
    "\n",
    "target = panel[\"target_ret_5d_fwd\"].dropna()\n",
    "print(f\"Target rows: {len(target)}\")\n",
    "print(f\"Mean: {target.mean():.3f}%   Std: {target.std():.3f}%\")\n",
    "print(f\"Skew: {target.skew():.3f}    Kurt: {target.kurtosis():.3f}\")\n",
    "\n",
    "fig = plot_target_distribution(target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10-corr-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_correlation_heatmap\n",
    "\n",
    "# Correlation of a subset of features\n",
    "corr_cols = [\"ret_1d\", \"ret_5d\", \"ret_20d\", \"vol_20d\", \"rsi_14\",\n",
    "             \"vix_level\", \"ism_pmi\", \"rolling_beta_60d\", \"target_ret_5d_fwd\"]\n",
    "corr_cols = [c for c in corr_cols if c in panel.columns]\n",
    "\n",
    "fig = plot_correlation_heatmap(panel[corr_cols].dropna(), title=\"Feature Correlations (incl. Target)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11-model-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Â· Train Models (Quick In-Sample Test)\n",
    "\n",
    "We first train each model on the **first 80%** of dates and evaluate on the remaining **20%**. This is **not** the final backtest â€” it's a quick sanity check to ensure the models learn something.\n",
    "\n",
    "> The real evaluation is the **walk-forward backtest** in Section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12-train-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import make_model, train_model, predict, get_feature_importance\n",
    "from src.metrics import compute_ml_metrics\n",
    "\n",
    "# â”€â”€ Train / test split on dates (NOT random!) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_dates = panel.index.get_level_values(\"date\").unique().sort_values()\n",
    "split_idx = int(len(all_dates) * 0.80)\n",
    "train_cutoff = all_dates[split_idx]\n",
    "\n",
    "train_mask = panel.index.get_level_values(\"date\") < train_cutoff\n",
    "test_mask  = panel.index.get_level_values(\"date\") >= train_cutoff\n",
    "\n",
    "feature_cols = [c for c in FEATURE_COLUMNS if c in panel.columns]\n",
    "train_data = panel[train_mask].dropna(subset=feature_cols + [\"target_ret_5d_fwd\"])\n",
    "test_data  = panel[test_mask].dropna(subset=feature_cols + [\"target_ret_5d_fwd\"])\n",
    "\n",
    "X_train, y_train = train_data[feature_cols], train_data[\"target_ret_5d_fwd\"]\n",
    "X_test,  y_test  = test_data[feature_cols],  test_data[\"target_ret_5d_fwd\"]\n",
    "\n",
    "print(f\"Train: {len(X_train)} rows ({X_train.index.get_level_values('date').min().date()} â†’ {train_cutoff.date()})\")\n",
    "print(f\"Test : {len(X_test)} rows ({train_cutoff.date()} â†’ {X_test.index.get_level_values('date').max().date()})\")\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name in [\"ridge\", \"rf\", \"xgboost\"]:\n",
    "    mdl = make_model(model_name)\n",
    "    mdl = train_model(mdl, X_train, y_train, X_val=X_test, y_val=y_test)\n",
    "    preds = predict(mdl, X_test)\n",
    "    metrics = compute_ml_metrics(y_test.values, preds)\n",
    "    model_results[model_name] = {\"model\": mdl, \"preds\": preds, \"metrics\": metrics}\n",
    "    print(f\"\\n{model_name.upper():10s}  MAE={metrics['mae']:.3f}  RMSE={metrics['rmse']:.3f}  \"\n",
    "          f\"IC={metrics['ic']:.3f}  HitRate={metrics['hit_rate']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13-feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_feature_importance\n",
    "\n",
    "# Show feature importance for each model\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for ax, (name, res) in zip(axes, model_results.items()):\n",
    "    imp = get_feature_importance(res[\"model\"], feature_names=feature_cols)\n",
    "    colors = [\"#2ca02c\" if v >= 0 else \"#d62728\" for v in imp.head(10)]\n",
    "    imp.head(10).sort_values().plot.barh(ax=ax, color=colors)\n",
    "    ax.set_title(f\"{name.upper()} â€” Top 10 Features\", fontsize=12)\n",
    "    ax.set_xlabel(\"Importance / |Coeff|\")\n",
    "    ax.grid(True, axis=\"x\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14-backtest-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 Â· Walk-Forward Backtest\n",
    "\n",
    "This is the **main evaluation**. The model is retrained every 13 weeks using an **expanding window** (all data up to the signal date). Predictions are generated for the following week's positions.\n",
    "\n",
    "**Anti-overfitting safeguards applied:**\n",
    "- Walk-forward (no future data ever seen during training)\n",
    "- Transaction costs: 5 bps + 2 bps slippage per trade\n",
    "- Top-K=3 positions (concentrated enough to test signal, diversified enough to reduce noise)\n",
    "- Only go long if predicted return > 0 (otherwise sit in cash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15-backtest-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.backtest import run_backtest, buy_and_hold_baseline\n",
    "from src.config import TICKERS, TOP_K, TRANSACTION_COST_BPS, SLIPPAGE_BPS\n",
    "\n",
    "# â”€â”€ Run backtest for all three models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "bt_results = {}\n",
    "for model_name in [\"ridge\", \"rf\", \"xgboost\"]:\n",
    "    print(f\"\\n{'â”€'*60}\")\n",
    "    print(f\"Running walk-forward backtest: {model_name.upper()}\")\n",
    "    bt_results[model_name] = run_backtest(\n",
    "        panel,\n",
    "        model_name=model_name,\n",
    "        top_k=TOP_K,\n",
    "        cost_bps=TRANSACTION_COST_BPS,\n",
    "        slippage_bps=SLIPPAGE_BPS,\n",
    "    )\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16-backtest-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import compute_trading_metrics\n",
    "\n",
    "print(\"\\n=== Walk-Forward Backtest Summary ===\")\n",
    "print(f\"{'Model':12s} {'Periods':>8s} {'CAGR%':>8s} {'Sharpe':>8s} {'MaxDD%':>8s} {'HitRate':>9s}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, df in bt_results.items():\n",
    "    if len(df) == 0:\n",
    "        print(f\"{name:12s}  NO RESULTS\")\n",
    "        continue\n",
    "    m = compute_trading_metrics(df[\"net_return_pct\"], df[\"cumulative_return\"])\n",
    "    print(f\"{name:12s} {len(df):>8d} {m['cagr']*100:>8.2f} {m['sharpe']:>8.2f} \"\n",
    "          f\"{m['max_drawdown']*100:>8.2f} {m['hit_rate']:>9.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17-equity-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_equity_curve\n",
    "from src.backtest import buy_and_hold_baseline\n",
    "\n",
    "# â”€â”€ Benchmark: IYT buy-and-hold over the same period â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Select model with most periods for the date range\n",
    "best_model_name = max(bt_results, key=lambda k: len(bt_results[k]))\n",
    "bt_df = bt_results[best_model_name]\n",
    "\n",
    "try:\n",
    "    bench = buy_and_hold_baseline(\n",
    "        panel,\n",
    "        ticker=\"IYT\",\n",
    "        start=bt_df.index[0],\n",
    "        end=bt_df.index[-1],\n",
    "    )\n",
    "except KeyError:\n",
    "    bench = None\n",
    "    print(\"IYT not found in panel â€” plotting strategy only\")\n",
    "\n",
    "# Align benchmark to strategy dates\n",
    "bench_aligned = None\n",
    "if bench is not None:\n",
    "    common_dates = bt_df.index.intersection(bench.index)\n",
    "    if len(common_dates) > 0:\n",
    "        bench_aligned = bench.loc[common_dates, \"cumulative_return\"]\n",
    "    else:\n",
    "        bench_aligned = bench[\"cumulative_return\"]\n",
    "\n",
    "fig = plot_equity_curve(\n",
    "    strategy_cum=bt_df[\"cumulative_return\"],\n",
    "    benchmark_cum=bench_aligned,\n",
    "    title=f\"Walk-Forward Backtest â€” {best_model_name.upper()} vs IYT Buy & Hold\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "final_val = bt_df[\"cumulative_return\"].iloc[-1]\n",
    "print(f\"Strategy final value: ${10_000 * final_val:,.0f}  (started at $10,000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18-all-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Compare all three models on a single chart â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "\n",
    "colors_map = {\"ridge\": \"#1f77b4\", \"rf\": \"#2ca02c\", \"xgboost\": \"#d62728\"}\n",
    "for name, df in bt_results.items():\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    cum = df[\"cumulative_return\"] / df[\"cumulative_return\"].iloc[0] * 10_000\n",
    "    ax.plot(cum.index, cum.values, label=name.upper(), color=colors_map[name], linewidth=1.8)\n",
    "\n",
    "ax.axhline(10_000, color=\"gray\", linestyle=\"--\", linewidth=0.8, label=\"Break-even\")\n",
    "ax.set_title(\"All Models â€” Growth of $10,000\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Portfolio Value ($)\")\n",
    "ax.yaxis.set_major_formatter(matplotlib.ticker.StrMethodFormatter(\"${x:,.0f}\"))\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "import seaborn as sns; sns.despine()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19-signals-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 Â· Signal Heatmap\n",
    "\n",
    "Visualize what the model predicted for each stock each week. Green = bullish signal, red = bearish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20-signal-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_signal_heatmap\n",
    "from src.model import predict\n",
    "from src.backtest import get_rebalance_dates\n",
    "from src.config import TICKERS\n",
    "\n",
    "# Re-train the best model on the first 80% and predict on remaining dates\n",
    "# to show a realistic signal history\n",
    "feature_cols = [c for c in FEATURE_COLUMNS if c in panel.columns]\n",
    "best_mdl = model_results[\"ridge\"][\"model\"]  # use Ridge for clarity\n",
    "\n",
    "signal_rows = []\n",
    "rebal_dates = get_rebalance_dates(panel[panel.index.get_level_values(\"ticker\").isin(TICKERS)])\n",
    "rebal_dates = rebal_dates[rebal_dates >= train_cutoff]  # test period only\n",
    "\n",
    "for sig_date in rebal_dates:\n",
    "    mask = (\n",
    "        (panel.index.get_level_values(\"date\") == sig_date) &\n",
    "        (panel.index.get_level_values(\"ticker\").isin(TICKERS))\n",
    "    )\n",
    "    sig_data = panel[mask].dropna(subset=feature_cols)\n",
    "    if len(sig_data) == 0:\n",
    "        continue\n",
    "    preds = predict(best_mdl, sig_data)\n",
    "    tickers_at_date = sig_data.index.get_level_values(\"ticker\")\n",
    "    for t, p in zip(tickers_at_date, preds):\n",
    "        signal_rows.append({\"date\": sig_date, \"ticker\": t, \"predicted_ret\": p})\n",
    "\n",
    "signals_df = pd.DataFrame(signal_rows)\n",
    "print(f\"Signal table shape: {signals_df.shape}\")\n",
    "\n",
    "if len(signals_df) > 0:\n",
    "    fig = plot_signal_heatmap(signals_df, title=\"Ridge Regression â€” Weekly Predicted Returns (Test Period)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No signals to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21-risk-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 Â· Risk & Pitfall Checks\n",
    "\n",
    "Every quant model should pass these sanity checks before going live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22-pitfall-checks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import FEATURE_COLUMNS\n",
    "\n",
    "issues = []\n",
    "ok = []\n",
    "\n",
    "# 1. Target not in feature list\n",
    "if \"target_ret_5d_fwd\" not in FEATURE_COLUMNS:\n",
    "    ok.append(\"âœ“ Target 'target_ret_5d_fwd' is NOT in FEATURE_COLUMNS (no leakage)\")\n",
    "else:\n",
    "    issues.append(\"âœ— Target IS in FEATURE_COLUMNS â€” DATA LEAKAGE!\")\n",
    "\n",
    "# 2. No future data in features\n",
    "sample_ticker = TICKERS[0]\n",
    "try:\n",
    "    from src.features import add_return_features\n",
    "    ticker_data = panel.xs(sample_ticker, level=\"ticker\")[\"adj_close\"].sort_index()\n",
    "    midpoint_date = ticker_data.index[len(ticker_data)//2]\n",
    "\n",
    "    df_full = panel.copy()\n",
    "    df_trunc = panel[panel.index.get_level_values(\"date\") <= midpoint_date].copy()\n",
    "\n",
    "    ret_full  = df_full.xs(sample_ticker, level=\"ticker\")[\"ret_5d\"].get(midpoint_date)\n",
    "    ret_trunc = df_trunc.xs(sample_ticker, level=\"ticker\")[\"ret_5d\"].get(midpoint_date)\n",
    "\n",
    "    if ret_full is not None and ret_trunc is not None:\n",
    "        if abs(float(ret_full) - float(ret_trunc)) < 1e-6:\n",
    "            ok.append(f\"âœ“ ret_5d at {midpoint_date.date()} unchanged when future data appended (no look-ahead)\")\n",
    "        else:\n",
    "            issues.append(f\"âœ— ret_5d CHANGED when future data appended â€” LOOK-AHEAD BIAS!\")\n",
    "    else:\n",
    "        ok.append(\"âœ“ Look-ahead check skipped (feature not present at midpoint date)\")\n",
    "except Exception as e:\n",
    "    ok.append(f\"âœ“ Look-ahead check skipped ({e})\")\n",
    "\n",
    "# 3. Transaction costs reduce returns\n",
    "best_bt = bt_results.get(\"ridge\", pd.DataFrame())\n",
    "if len(best_bt) > 0 and \"gross_return_pct\" in best_bt.columns and \"net_return_pct\" in best_bt.columns:\n",
    "    avg_cost = (best_bt[\"gross_return_pct\"] - best_bt[\"net_return_pct\"]).mean()\n",
    "    if avg_cost >= 0:\n",
    "        ok.append(f\"âœ“ Costs correctly reduce returns (avg cost per period: {avg_cost:.4f}%)\")\n",
    "    else:\n",
    "        issues.append(\"âœ— Costs are INCREASING returns â€” cost logic is wrong!\")\n",
    "\n",
    "# 4. Turnover is reasonable\n",
    "if len(best_bt) > 0 and \"turnover_frac\" in best_bt.columns:\n",
    "    avg_turnover = best_bt[\"turnover_frac\"].mean()\n",
    "    if 0 <= avg_turnover <= 1:\n",
    "        ok.append(f\"âœ“ Average turnover per period: {avg_turnover:.2%} (reasonable)\")\n",
    "    else:\n",
    "        issues.append(f\"âœ— Turnover {avg_turnover:.2%} outside [0,1]!\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PITFALL CHECKLIST\")\n",
    "print(\"=\" * 60)\n",
    "for item in ok:\n",
    "    print(item)\n",
    "for item in issues:\n",
    "    print(item)\n",
    "if not issues:\n",
    "    print(\"\\nâœ“ All checks passed.\")\n",
    "else:\n",
    "    print(f\"\\nâœ— {len(issues)} issue(s) found â€” fix before trusting results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23-cumreturns-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 Â· Cumulative Return Comparison (Tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24-cumreturns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_cumulative_returns\n",
    "\n",
    "fig = plot_cumulative_returns(\n",
    "    prices_long=panel,\n",
    "    tickers=TICKERS[:6],  # first 6 for readability\n",
    "    title=\"Cumulative Price Returns â€” Supply-Chain Universe\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25-save-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8 Â· Save Best Model\n",
    "\n",
    "Save the best-performing model to disk so the Streamlit app can load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26-save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import make_model, train_model, save_model\n",
    "\n",
    "# Retrain on the full dataset before saving\n",
    "full_data = panel.dropna(subset=feature_cols + [\"target_ret_5d_fwd\"])\n",
    "X_full = full_data[feature_cols]\n",
    "y_full = full_data[\"target_ret_5d_fwd\"]\n",
    "\n",
    "for name in [\"ridge\", \"rf\", \"xgboost\"]:\n",
    "    mdl = make_model(name)\n",
    "    mdl = train_model(mdl, X_full, y_full)\n",
    "    path = save_model(mdl, name, suffix=\"_full\")\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "print(\"\\nAll models saved âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27-next-steps",
   "metadata": {},
   "source": [
    "---\n",
    "## 9 Â· Next Steps\n",
    "\n",
    "| Step | Description |\n",
    "|---|---|\n",
    "| ðŸš€ **Run the App** | `streamlit run app/app.py` in the terminal |\n",
    "| ðŸ§ª **Run Tests** | `pytest tests/ -v` |\n",
    "| ðŸ“¦ **Deploy** | Push to GitHub â†’ Railway auto-deploys via Dockerfile |\n",
    "| ðŸ”§ **Tune** | Adjust `TOP_K`, `TRANSACTION_COST_BPS`, or model hyper-params in `src/config.py` |\n",
    "| ðŸ“ˆ **Extend** | Add new features, new tickers, or try a classification approach |\n",
    "\n",
    "### Biases to Keep Monitoring\n",
    "- **Look-ahead bias**: always use data strictly before the signal date\n",
    "- **Survivorship bias**: this universe is point-in-time curated; add delisted tickers for production\n",
    "- **Overfitting**: IC on the test period should remain positive across multiple runs\n",
    "- **Transaction costs**: always verify net > gross at reasonable cost assumptions\n",
    "\n",
    "---\n",
    "_Generated by SCL-Alpha blueprint â€” see `ml-quant-trading-blueprint.md` for full methodology._"
   ]
  }
 ]
}
